# 一个简单的中文分词器
* 课程作业，仅供娱乐
* 使用两层Bilstm和一层Attention，模型很小
* 训练和模型调用见main.ipynb
* 使用pku中文分词数据集训练，acc(micro-F1) 约93.2
## 模型效果实例
```
# input
感谢复旦大学自然语言处理实验室的黄老师和几位助教的指导，我在本次实验中收获了很多
# output
['感谢', '复旦', '大学', '自然', '语言', '处理', '实验室', '的', '黄', '老师', '和', '几', '位', '助教', '的', '指导', '，', '我', '在', '本次', '实验', '中', '收获', '了', '很多']
```